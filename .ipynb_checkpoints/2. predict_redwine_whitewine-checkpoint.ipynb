{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leesoojin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import keras.backend.tensorflow_backend as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import os\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1     2    3      4     5     6       7     8     9    10  11  12\n",
      "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
      "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
      "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1\n",
      "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   6   1\n",
      "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./dataset/wine.csv', header=None)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      "0     6497 non-null float64\n",
      "1     6497 non-null float64\n",
      "2     6497 non-null float64\n",
      "3     6497 non-null float64\n",
      "4     6497 non-null float64\n",
      "5     6497 non-null float64\n",
      "6     6497 non-null float64\n",
      "7     6497 non-null float64\n",
      "8     6497 non-null float64\n",
      "9     6497 non-null float64\n",
      "10    6497 non-null float64\n",
      "11    6497 non-null int64\n",
      "12    6497 non-null int64\n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 659.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.400e+00 7.000e-01 0.000e+00 1.900e+00 7.600e-02 1.100e+01 3.400e+01\n",
      "  9.978e-01 3.510e+00 5.600e-01 9.400e+00 5.000e+00]\n",
      " [7.800e+00 8.800e-01 0.000e+00 2.600e+00 9.800e-02 2.500e+01 6.700e+01\n",
      "  9.968e-01 3.200e+00 6.800e-01 9.800e+00 5.000e+00]\n",
      " [7.800e+00 7.600e-01 4.000e-02 2.300e+00 9.200e-02 1.500e+01 5.400e+01\n",
      "  9.970e-01 3.260e+00 6.500e-01 9.800e+00 5.000e+00]\n",
      " [1.120e+01 2.800e-01 5.600e-01 1.900e+00 7.500e-02 1.700e+01 6.000e+01\n",
      "  9.980e-01 3.160e+00 5.800e-01 9.800e+00 6.000e+00]\n",
      " [7.400e+00 7.000e-01 0.000e+00 1.900e+00 7.600e-02 1.100e+01 3.400e+01\n",
      "  9.978e-01 3.510e+00 5.600e-01 9.400e+00 5.000e+00]]\n",
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, 0:12].values\n",
    "y = data.iloc[:, 12].values\n",
    "\n",
    "\n",
    "\n",
    "print(X[:5])\n",
    "print(y[:5])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3637 samples, validate on 910 samples\n",
      "Epoch 1/500\n",
      "3637/3637 [==============================] - 1s 165us/step - loss: 4.1750 - acc: 0.5180 - val_loss: 1.5833 - val_acc: 0.7670\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.58329, saving model to ./model/model_day4.model\n",
      "Epoch 2/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 1.0648 - acc: 0.7751 - val_loss: 0.6523 - val_acc: 0.7538\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.58329 to 0.65228, saving model to ./model/model_day4.model\n",
      "Epoch 3/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.4293 - acc: 0.8243 - val_loss: 0.2750 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65228 to 0.27497, saving model to ./model/model_day4.model\n",
      "Epoch 4/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.2372 - acc: 0.9073 - val_loss: 0.2193 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.27497 to 0.21929, saving model to ./model/model_day4.model\n",
      "Epoch 5/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.2058 - acc: 0.9247 - val_loss: 0.2125 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21929 to 0.21253, saving model to ./model/model_day4.model\n",
      "Epoch 6/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.2043 - acc: 0.9233 - val_loss: 0.2101 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.21253 to 0.21008, saving model to ./model/model_day4.model\n",
      "Epoch 7/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1966 - acc: 0.9274 - val_loss: 0.2043 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21008 to 0.20428, saving model to ./model/model_day4.model\n",
      "Epoch 8/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1923 - acc: 0.9296 - val_loss: 0.2002 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.20428 to 0.20015, saving model to ./model/model_day4.model\n",
      "Epoch 9/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1910 - acc: 0.9313 - val_loss: 0.1988 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.20015 to 0.19880, saving model to ./model/model_day4.model\n",
      "Epoch 10/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1925 - acc: 0.9313 - val_loss: 0.1931 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19880 to 0.19310, saving model to ./model/model_day4.model\n",
      "Epoch 11/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1847 - acc: 0.9299 - val_loss: 0.1884 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.19310 to 0.18838, saving model to ./model/model_day4.model\n",
      "Epoch 12/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1805 - acc: 0.9315 - val_loss: 0.1848 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18838 to 0.18476, saving model to ./model/model_day4.model\n",
      "Epoch 13/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.1798 - acc: 0.9351 - val_loss: 0.1804 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.18476 to 0.18044, saving model to ./model/model_day4.model\n",
      "Epoch 14/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1738 - acc: 0.9370 - val_loss: 0.1778 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.18044 to 0.17781, saving model to ./model/model_day4.model\n",
      "Epoch 15/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.1712 - acc: 0.9412 - val_loss: 0.1773 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17781 to 0.17732, saving model to ./model/model_day4.model\n",
      "Epoch 16/500\n",
      "3637/3637 [==============================] - 0s 29us/step - loss: 0.1692 - acc: 0.9395 - val_loss: 0.1712 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.17732 to 0.17121, saving model to ./model/model_day4.model\n",
      "Epoch 17/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.1642 - acc: 0.9414 - val_loss: 0.1675 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.17121 to 0.16751, saving model to ./model/model_day4.model\n",
      "Epoch 18/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1632 - acc: 0.9434 - val_loss: 0.1707 - val_acc: 0.9495\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16751\n",
      "Epoch 19/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1617 - acc: 0.9417 - val_loss: 0.1633 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.16751 to 0.16328, saving model to ./model/model_day4.model\n",
      "Epoch 20/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1600 - acc: 0.9409 - val_loss: 0.1574 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.16328 to 0.15738, saving model to ./model/model_day4.model\n",
      "Epoch 21/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1563 - acc: 0.9475 - val_loss: 0.1566 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15738 to 0.15659, saving model to ./model/model_day4.model\n",
      "Epoch 22/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.1517 - acc: 0.9486 - val_loss: 0.1518 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.15659 to 0.15179, saving model to ./model/model_day4.model\n",
      "Epoch 23/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1515 - acc: 0.9467 - val_loss: 0.1489 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.15179 to 0.14889, saving model to ./model/model_day4.model\n",
      "Epoch 24/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1466 - acc: 0.9497 - val_loss: 0.1462 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14889 to 0.14615, saving model to ./model/model_day4.model\n",
      "Epoch 25/500\n",
      "3637/3637 [==============================] - 0s 29us/step - loss: 0.1446 - acc: 0.9505 - val_loss: 0.1497 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.14615\n",
      "Epoch 26/500\n",
      "3637/3637 [==============================] - 0s 28us/step - loss: 0.1444 - acc: 0.9508 - val_loss: 0.1425 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.14615 to 0.14248, saving model to ./model/model_day4.model\n",
      "Epoch 27/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1411 - acc: 0.9522 - val_loss: 0.1439 - val_acc: 0.9495\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14248\n",
      "Epoch 28/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1389 - acc: 0.9513 - val_loss: 0.1358 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14248 to 0.13581, saving model to ./model/model_day4.model\n",
      "Epoch 29/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1362 - acc: 0.9546 - val_loss: 0.1339 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.13581 to 0.13392, saving model to ./model/model_day4.model\n",
      "Epoch 30/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.1341 - acc: 0.9535 - val_loss: 0.1311 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.13392 to 0.13114, saving model to ./model/model_day4.model\n",
      "Epoch 31/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1355 - acc: 0.9533 - val_loss: 0.1347 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.13114\n",
      "Epoch 32/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.1341 - acc: 0.9546 - val_loss: 0.1309 - val_acc: 0.9538\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.13114 to 0.13089, saving model to ./model/model_day4.model\n",
      "Epoch 33/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.1317 - acc: 0.9530 - val_loss: 0.1250 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.13089 to 0.12501, saving model to ./model/model_day4.model\n",
      "Epoch 34/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1265 - acc: 0.9568 - val_loss: 0.1237 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.12501 to 0.12372, saving model to ./model/model_day4.model\n",
      "Epoch 35/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.1253 - acc: 0.9568 - val_loss: 0.1200 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.12372 to 0.11995, saving model to ./model/model_day4.model\n",
      "Epoch 36/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1239 - acc: 0.9560 - val_loss: 0.1181 - val_acc: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: val_loss improved from 0.11995 to 0.11808, saving model to ./model/model_day4.model\n",
      "Epoch 37/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1230 - acc: 0.9585 - val_loss: 0.1157 - val_acc: 0.9604\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.11808 to 0.11568, saving model to ./model/model_day4.model\n",
      "Epoch 38/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1197 - acc: 0.9601 - val_loss: 0.1159 - val_acc: 0.9615\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11568\n",
      "Epoch 39/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1206 - acc: 0.9568 - val_loss: 0.1273 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11568\n",
      "Epoch 40/500\n",
      "3637/3637 [==============================] - ETA: 0s - loss: 0.1232 - acc: 0.960 - 0s 23us/step - loss: 0.1228 - acc: 0.9604 - val_loss: 0.1096 - val_acc: 0.9615\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.11568 to 0.10963, saving model to ./model/model_day4.model\n",
      "Epoch 41/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1153 - acc: 0.9599 - val_loss: 0.1078 - val_acc: 0.9604\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.10963 to 0.10778, saving model to ./model/model_day4.model\n",
      "Epoch 42/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1122 - acc: 0.9618 - val_loss: 0.1117 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.10778\n",
      "Epoch 43/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.1132 - acc: 0.9601 - val_loss: 0.1058 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.10778 to 0.10584, saving model to ./model/model_day4.model\n",
      "Epoch 44/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.1099 - acc: 0.9621 - val_loss: 0.1024 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.10584 to 0.10238, saving model to ./model/model_day4.model\n",
      "Epoch 45/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1085 - acc: 0.9643 - val_loss: 0.1003 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.10238 to 0.10029, saving model to ./model/model_day4.model\n",
      "Epoch 46/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1078 - acc: 0.9623 - val_loss: 0.0991 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.10029 to 0.09914, saving model to ./model/model_day4.model\n",
      "Epoch 47/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.1097 - acc: 0.9632 - val_loss: 0.0986 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.09914 to 0.09855, saving model to ./model/model_day4.model\n",
      "Epoch 48/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.1048 - acc: 0.9648 - val_loss: 0.0955 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.09855 to 0.09553, saving model to ./model/model_day4.model\n",
      "Epoch 49/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.1040 - acc: 0.9634 - val_loss: 0.0963 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.09553\n",
      "Epoch 50/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1039 - acc: 0.9654 - val_loss: 0.0952 - val_acc: 0.9582\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.09553 to 0.09518, saving model to ./model/model_day4.model\n",
      "Epoch 51/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1007 - acc: 0.9656 - val_loss: 0.0927 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.09518 to 0.09267, saving model to ./model/model_day4.model\n",
      "Epoch 52/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0994 - acc: 0.9673 - val_loss: 0.0894 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.09267 to 0.08936, saving model to ./model/model_day4.model\n",
      "Epoch 53/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1041 - acc: 0.9654 - val_loss: 0.0880 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.08936 to 0.08805, saving model to ./model/model_day4.model\n",
      "Epoch 54/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0975 - acc: 0.9673 - val_loss: 0.0870 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.08805 to 0.08702, saving model to ./model/model_day4.model\n",
      "Epoch 55/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0959 - acc: 0.9681 - val_loss: 0.0900 - val_acc: 0.9604\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.08702\n",
      "Epoch 56/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0951 - acc: 0.9676 - val_loss: 0.0933 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.08702\n",
      "Epoch 57/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0946 - acc: 0.9656 - val_loss: 0.0830 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.08702 to 0.08303, saving model to ./model/model_day4.model\n",
      "Epoch 58/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0923 - acc: 0.9687 - val_loss: 0.0820 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.08303 to 0.08196, saving model to ./model/model_day4.model\n",
      "Epoch 59/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0924 - acc: 0.9695 - val_loss: 0.0815 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.08196 to 0.08148, saving model to ./model/model_day4.model\n",
      "Epoch 60/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0914 - acc: 0.9709 - val_loss: 0.0850 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.08148\n",
      "Epoch 61/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0903 - acc: 0.9711 - val_loss: 0.0775 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08148 to 0.07754, saving model to ./model/model_day4.model\n",
      "Epoch 62/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0893 - acc: 0.9717 - val_loss: 0.0828 - val_acc: 0.9648\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.07754\n",
      "Epoch 63/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0901 - acc: 0.9706 - val_loss: 0.0802 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.07754\n",
      "Epoch 64/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0888 - acc: 0.9728 - val_loss: 0.0747 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07754 to 0.07468, saving model to ./model/model_day4.model\n",
      "Epoch 65/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0856 - acc: 0.9714 - val_loss: 0.0741 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07468 to 0.07407, saving model to ./model/model_day4.model\n",
      "Epoch 66/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0872 - acc: 0.9725 - val_loss: 0.0726 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07407 to 0.07258, saving model to ./model/model_day4.model\n",
      "Epoch 67/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0838 - acc: 0.9733 - val_loss: 0.0725 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07258 to 0.07250, saving model to ./model/model_day4.model\n",
      "Epoch 68/500\n",
      "3637/3637 [==============================] - 0s 29us/step - loss: 0.0860 - acc: 0.9733 - val_loss: 0.0710 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07250 to 0.07097, saving model to ./model/model_day4.model\n",
      "Epoch 69/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0826 - acc: 0.9742 - val_loss: 0.0719 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.07097\n",
      "Epoch 70/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0872 - acc: 0.9725 - val_loss: 0.0882 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.07097\n",
      "Epoch 71/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0917 - acc: 0.9703 - val_loss: 0.0691 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.07097 to 0.06910, saving model to ./model/model_day4.model\n",
      "Epoch 72/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0827 - acc: 0.9720 - val_loss: 0.0806 - val_acc: 0.9648\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06910\n",
      "Epoch 73/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.1005 - acc: 0.9651 - val_loss: 0.0696 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06910\n",
      "Epoch 74/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0834 - acc: 0.9733 - val_loss: 0.0656 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06910 to 0.06564, saving model to ./model/model_day4.model\n",
      "Epoch 75/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0790 - acc: 0.9753 - val_loss: 0.0645 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06564 to 0.06450, saving model to ./model/model_day4.model\n",
      "Epoch 76/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0783 - acc: 0.9769 - val_loss: 0.0654 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.06450\n",
      "Epoch 77/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.0777 - acc: 0.9772 - val_loss: 0.0636 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06450 to 0.06364, saving model to ./model/model_day4.model\n",
      "Epoch 78/500\n",
      "3637/3637 [==============================] - ETA: 0s - loss: 0.0813 - acc: 0.975 - 0s 24us/step - loss: 0.0846 - acc: 0.9731 - val_loss: 0.0638 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06364\n",
      "Epoch 79/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0754 - acc: 0.9766 - val_loss: 0.0620 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.06364 to 0.06197, saving model to ./model/model_day4.model\n",
      "Epoch 80/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0775 - acc: 0.9755 - val_loss: 0.0674 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06197\n",
      "Epoch 81/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0746 - acc: 0.9772 - val_loss: 0.0601 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.06197 to 0.06013, saving model to ./model/model_day4.model\n",
      "Epoch 82/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0753 - acc: 0.9747 - val_loss: 0.0597 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06013 to 0.05969, saving model to ./model/model_day4.model\n",
      "Epoch 83/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0784 - acc: 0.9753 - val_loss: 0.0591 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05969 to 0.05907, saving model to ./model/model_day4.model\n",
      "Epoch 84/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0730 - acc: 0.9772 - val_loss: 0.0613 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.05907\n",
      "Epoch 85/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0715 - acc: 0.9794 - val_loss: 0.0736 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.05907\n",
      "Epoch 86/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0731 - acc: 0.9783 - val_loss: 0.0576 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05907 to 0.05757, saving model to ./model/model_day4.model\n",
      "Epoch 87/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0711 - acc: 0.9797 - val_loss: 0.0571 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05757 to 0.05711, saving model to ./model/model_day4.model\n",
      "Epoch 88/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0719 - acc: 0.9780 - val_loss: 0.0571 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05711 to 0.05711, saving model to ./model/model_day4.model\n",
      "Epoch 89/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0725 - acc: 0.9777 - val_loss: 0.0622 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05711\n",
      "Epoch 90/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0761 - acc: 0.9758 - val_loss: 0.0625 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05711\n",
      "Epoch 91/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0854 - acc: 0.9736 - val_loss: 0.0556 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05711 to 0.05558, saving model to ./model/model_day4.model\n",
      "Epoch 92/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0750 - acc: 0.9753 - val_loss: 0.0588 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05558\n",
      "Epoch 93/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0724 - acc: 0.9772 - val_loss: 0.0547 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05558 to 0.05469, saving model to ./model/model_day4.model\n",
      "Epoch 94/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0773 - acc: 0.9761 - val_loss: 0.0792 - val_acc: 0.9670\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05469\n",
      "Epoch 95/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0791 - acc: 0.9742 - val_loss: 0.0534 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.05469 to 0.05337, saving model to ./model/model_day4.model\n",
      "Epoch 96/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0704 - acc: 0.9791 - val_loss: 0.0545 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05337\n",
      "Epoch 97/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0691 - acc: 0.9780 - val_loss: 0.0574 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05337\n",
      "Epoch 98/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0689 - acc: 0.9791 - val_loss: 0.0607 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05337\n",
      "Epoch 99/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0659 - acc: 0.9791 - val_loss: 0.0521 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05337 to 0.05215, saving model to ./model/model_day4.model\n",
      "Epoch 100/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0655 - acc: 0.9791 - val_loss: 0.0521 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.05215 to 0.05205, saving model to ./model/model_day4.model\n",
      "Epoch 101/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0654 - acc: 0.9808 - val_loss: 0.0524 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.05205\n",
      "Epoch 102/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0677 - acc: 0.9777 - val_loss: 0.0525 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05205\n",
      "Epoch 103/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0647 - acc: 0.9794 - val_loss: 0.0532 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.05205\n",
      "Epoch 104/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0654 - acc: 0.9791 - val_loss: 0.0515 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.05205 to 0.05153, saving model to ./model/model_day4.model\n",
      "Epoch 105/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0639 - acc: 0.9802 - val_loss: 0.0509 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.05153 to 0.05092, saving model to ./model/model_day4.model\n",
      "Epoch 106/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0669 - acc: 0.9794 - val_loss: 0.0582 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.05092\n",
      "Epoch 107/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.9783 - val_loss: 0.0536 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.05092\n",
      "Epoch 108/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0673 - acc: 0.9786 - val_loss: 0.0524 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.05092\n",
      "Epoch 109/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0647 - acc: 0.9799 - val_loss: 0.0728 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.05092\n",
      "Epoch 110/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0722 - acc: 0.9777 - val_loss: 0.0572 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.05092\n",
      "Epoch 111/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0967 - acc: 0.9698 - val_loss: 0.0668 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.05092\n",
      "Epoch 112/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0766 - acc: 0.9777 - val_loss: 0.0498 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.05092 to 0.04978, saving model to ./model/model_day4.model\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0631 - acc: 0.9810 - val_loss: 0.0544 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04978\n",
      "Epoch 114/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0633 - acc: 0.9808 - val_loss: 0.0598 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.04978\n",
      "Epoch 115/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0640 - acc: 0.9794 - val_loss: 0.0815 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04978\n",
      "Epoch 116/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0662 - acc: 0.9797 - val_loss: 0.0517 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.04978\n",
      "Epoch 117/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0640 - acc: 0.9810 - val_loss: 0.0491 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.04978 to 0.04909, saving model to ./model/model_day4.model\n",
      "Epoch 118/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0629 - acc: 0.9788 - val_loss: 0.0704 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.04909\n",
      "Epoch 119/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0641 - acc: 0.9805 - val_loss: 0.0489 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.04909 to 0.04886, saving model to ./model/model_day4.model\n",
      "Epoch 120/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0607 - acc: 0.9819 - val_loss: 0.0503 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.04886\n",
      "Epoch 121/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0636 - acc: 0.9780 - val_loss: 0.0544 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.04886\n",
      "Epoch 122/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0655 - acc: 0.9794 - val_loss: 0.0516 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.04886\n",
      "Epoch 123/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0609 - acc: 0.9802 - val_loss: 0.0487 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.04886 to 0.04873, saving model to ./model/model_day4.model\n",
      "Epoch 124/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0621 - acc: 0.9810 - val_loss: 0.0529 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.04873\n",
      "Epoch 125/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0617 - acc: 0.9816 - val_loss: 0.0499 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.04873\n",
      "Epoch 126/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0665 - acc: 0.9810 - val_loss: 0.0492 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.04873\n",
      "Epoch 127/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0622 - acc: 0.9813 - val_loss: 0.0508 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.04873\n",
      "Epoch 128/500\n",
      "3637/3637 [==============================] - 0s 30us/step - loss: 0.0646 - acc: 0.9799 - val_loss: 0.0507 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04873\n",
      "Epoch 129/500\n",
      "3637/3637 [==============================] - 0s 35us/step - loss: 0.0633 - acc: 0.9805 - val_loss: 0.0527 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.04873\n",
      "Epoch 130/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0593 - acc: 0.9808 - val_loss: 0.0510 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.04873\n",
      "Epoch 131/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0613 - acc: 0.9824 - val_loss: 0.0811 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.04873\n",
      "Epoch 132/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0760 - acc: 0.9766 - val_loss: 0.0499 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.04873\n",
      "Epoch 133/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0600 - acc: 0.9821 - val_loss: 0.0538 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04873\n",
      "Epoch 134/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0595 - acc: 0.9838 - val_loss: 0.0537 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.04873\n",
      "Epoch 135/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.0619 - acc: 0.9821 - val_loss: 0.0691 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04873\n",
      "Epoch 136/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0638 - acc: 0.9799 - val_loss: 0.0514 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04873\n",
      "Epoch 137/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0608 - acc: 0.9821 - val_loss: 0.0477 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.04873 to 0.04772, saving model to ./model/model_day4.model\n",
      "Epoch 138/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0578 - acc: 0.9799 - val_loss: 0.0559 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04772\n",
      "Epoch 139/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0630 - acc: 0.9797 - val_loss: 0.0541 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04772\n",
      "Epoch 140/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0611 - acc: 0.9816 - val_loss: 0.0503 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04772\n",
      "Epoch 141/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0636 - acc: 0.9808 - val_loss: 0.0546 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04772\n",
      "Epoch 142/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0577 - acc: 0.9821 - val_loss: 0.0470 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.04772 to 0.04700, saving model to ./model/model_day4.model\n",
      "Epoch 143/500\n",
      "3637/3637 [==============================] - 0s 30us/step - loss: 0.0563 - acc: 0.9838 - val_loss: 0.0468 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.04700 to 0.04678, saving model to ./model/model_day4.model\n",
      "Epoch 144/500\n",
      "3637/3637 [==============================] - 0s 30us/step - loss: 0.0569 - acc: 0.9821 - val_loss: 0.0517 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.04678\n",
      "Epoch 145/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0622 - acc: 0.9810 - val_loss: 0.0462 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.04678 to 0.04616, saving model to ./model/model_day4.model\n",
      "Epoch 146/500\n",
      "3637/3637 [==============================] - 0s 28us/step - loss: 0.0598 - acc: 0.9816 - val_loss: 0.0472 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.04616\n",
      "Epoch 147/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0580 - acc: 0.9832 - val_loss: 0.0478 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.04616\n",
      "Epoch 148/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0589 - acc: 0.9830 - val_loss: 0.0519 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.04616\n",
      "Epoch 149/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0571 - acc: 0.9832 - val_loss: 0.0588 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04616\n",
      "Epoch 150/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0640 - acc: 0.9810 - val_loss: 0.0478 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.04616\n",
      "Epoch 151/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0582 - acc: 0.9824 - val_loss: 0.0582 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.04616\n",
      "Epoch 152/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0748 - acc: 0.9766 - val_loss: 0.0599 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.04616\n",
      "Epoch 153/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0628 - acc: 0.9810 - val_loss: 0.0621 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.04616\n",
      "Epoch 154/500\n",
      "3637/3637 [==============================] - 0s 29us/step - loss: 0.0607 - acc: 0.9810 - val_loss: 0.0551 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.04616\n",
      "Epoch 155/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0577 - acc: 0.9816 - val_loss: 0.0503 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.04616\n",
      "Epoch 156/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.0645 - acc: 0.9797 - val_loss: 0.0604 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.04616\n",
      "Epoch 157/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0586 - acc: 0.9788 - val_loss: 0.0469 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.04616\n",
      "Epoch 158/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0638 - acc: 0.9797 - val_loss: 0.0468 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.04616\n",
      "Epoch 159/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0556 - acc: 0.9827 - val_loss: 0.0465 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.04616\n",
      "Epoch 160/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0551 - acc: 0.9830 - val_loss: 0.0470 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.04616\n",
      "Epoch 161/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0561 - acc: 0.9835 - val_loss: 0.0552 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.04616\n",
      "Epoch 162/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0552 - acc: 0.9849 - val_loss: 0.0548 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.04616\n",
      "Epoch 163/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0564 - acc: 0.9835 - val_loss: 0.0743 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.04616\n",
      "Epoch 164/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0577 - acc: 0.9816 - val_loss: 0.0473 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.04616\n",
      "Epoch 165/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0590 - acc: 0.9813 - val_loss: 0.0497 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.04616\n",
      "Epoch 166/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0577 - acc: 0.9821 - val_loss: 0.0503 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.04616\n",
      "Epoch 167/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0574 - acc: 0.9821 - val_loss: 0.0459 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.04616 to 0.04585, saving model to ./model/model_day4.model\n",
      "Epoch 168/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0585 - acc: 0.9816 - val_loss: 0.0587 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.04585\n",
      "Epoch 169/500\n",
      "3637/3637 [==============================] - 0s 28us/step - loss: 0.0569 - acc: 0.9816 - val_loss: 0.0463 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.04585\n",
      "Epoch 170/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0556 - acc: 0.9838 - val_loss: 0.0461 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.04585\n",
      "Epoch 171/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0547 - acc: 0.9824 - val_loss: 0.0461 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.04585\n",
      "Epoch 172/500\n",
      "3637/3637 [==============================] - 0s 28us/step - loss: 0.0537 - acc: 0.9841 - val_loss: 0.0502 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.04585\n",
      "Epoch 173/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0584 - acc: 0.9819 - val_loss: 0.0689 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.04585\n",
      "Epoch 174/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0639 - acc: 0.9802 - val_loss: 0.0456 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.04585 to 0.04560, saving model to ./model/model_day4.model\n",
      "Epoch 175/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0542 - acc: 0.9849 - val_loss: 0.0504 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.04560\n",
      "Epoch 176/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0550 - acc: 0.9824 - val_loss: 0.0616 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.04560\n",
      "Epoch 177/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0562 - acc: 0.9830 - val_loss: 0.0742 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.04560\n",
      "Epoch 178/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0658 - acc: 0.9794 - val_loss: 0.0459 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.04560\n",
      "Epoch 179/500\n",
      "3637/3637 [==============================] - 0s 28us/step - loss: 0.0669 - acc: 0.9802 - val_loss: 0.0457 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.04560\n",
      "Epoch 180/500\n",
      "3637/3637 [==============================] - 0s 28us/step - loss: 0.0582 - acc: 0.9810 - val_loss: 0.0513 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.04560\n",
      "Epoch 181/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0625 - acc: 0.9802 - val_loss: 0.0468 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.04560\n",
      "Epoch 182/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0547 - acc: 0.9841 - val_loss: 0.0491 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.04560\n",
      "Epoch 183/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0555 - acc: 0.9835 - val_loss: 0.0496 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.04560\n",
      "Epoch 184/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0556 - acc: 0.9821 - val_loss: 0.0472 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.04560\n",
      "Epoch 185/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0538 - acc: 0.9827 - val_loss: 0.0501 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.04560\n",
      "Epoch 186/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0570 - acc: 0.9816 - val_loss: 0.0464 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.04560\n",
      "Epoch 187/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0670 - acc: 0.9777 - val_loss: 0.0462 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.04560\n",
      "Epoch 188/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0527 - acc: 0.9838 - val_loss: 0.0492 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.04560\n",
      "Epoch 189/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0528 - acc: 0.9835 - val_loss: 0.0501 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.04560\n",
      "Epoch 190/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0561 - acc: 0.9835 - val_loss: 0.0467 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.04560\n",
      "Epoch 191/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0546 - acc: 0.9835 - val_loss: 0.0501 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.04560\n",
      "Epoch 192/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0547 - acc: 0.9838 - val_loss: 0.0622 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.04560\n",
      "Epoch 193/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0626 - acc: 0.9805 - val_loss: 0.0460 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.04560\n",
      "Epoch 194/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0539 - acc: 0.9854 - val_loss: 0.0495 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.04560\n",
      "Epoch 195/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0587 - acc: 0.9830 - val_loss: 0.0540 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.04560\n",
      "Epoch 196/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0560 - acc: 0.9832 - val_loss: 0.0511 - val_acc: 0.9813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00196: val_loss did not improve from 0.04560\n",
      "Epoch 197/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0534 - acc: 0.9832 - val_loss: 0.0497 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.04560\n",
      "Epoch 198/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0607 - acc: 0.9805 - val_loss: 0.0529 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.04560\n",
      "Epoch 199/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0520 - acc: 0.9841 - val_loss: 0.0455 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.04560 to 0.04552, saving model to ./model/model_day4.model\n",
      "Epoch 200/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0519 - acc: 0.9849 - val_loss: 0.0466 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.04552\n",
      "Epoch 201/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.0602 - acc: 0.9805 - val_loss: 0.0497 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.04552\n",
      "Epoch 202/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0628 - acc: 0.9810 - val_loss: 0.0457 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.04552\n",
      "Epoch 203/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0555 - acc: 0.9830 - val_loss: 0.0551 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.04552\n",
      "Epoch 204/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0535 - acc: 0.9830 - val_loss: 0.0470 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.04552\n",
      "Epoch 205/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0527 - acc: 0.9824 - val_loss: 0.0546 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.04552\n",
      "Epoch 206/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0536 - acc: 0.9854 - val_loss: 0.0502 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.04552\n",
      "Epoch 207/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0581 - acc: 0.9835 - val_loss: 0.0460 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.04552\n",
      "Epoch 208/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0545 - acc: 0.9838 - val_loss: 0.0466 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.04552\n",
      "Epoch 209/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0550 - acc: 0.9832 - val_loss: 0.0486 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.04552\n",
      "Epoch 210/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0514 - acc: 0.9832 - val_loss: 0.0478 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.04552\n",
      "Epoch 211/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0512 - acc: 0.9835 - val_loss: 0.0468 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.04552\n",
      "Epoch 212/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0518 - acc: 0.9843 - val_loss: 0.0467 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.04552\n",
      "Epoch 213/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.0516 - acc: 0.9832 - val_loss: 0.0524 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.04552\n",
      "Epoch 214/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0508 - acc: 0.9849 - val_loss: 0.0481 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.04552\n",
      "Epoch 215/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.0514 - acc: 0.9846 - val_loss: 0.0551 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.04552\n",
      "Epoch 216/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0567 - acc: 0.9830 - val_loss: 0.0572 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.04552\n",
      "Epoch 217/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.0540 - acc: 0.9843 - val_loss: 0.0484 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.04552\n",
      "Epoch 218/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0540 - acc: 0.9819 - val_loss: 0.0486 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.04552\n",
      "Epoch 219/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0550 - acc: 0.9824 - val_loss: 0.0499 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.04552\n",
      "Epoch 220/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0555 - acc: 0.9838 - val_loss: 0.0479 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.04552\n",
      "Epoch 221/500\n",
      "3637/3637 [==============================] - 0s 22us/step - loss: 0.0517 - acc: 0.9849 - val_loss: 0.0480 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.04552\n",
      "Epoch 222/500\n",
      "3637/3637 [==============================] - 0s 28us/step - loss: 0.0510 - acc: 0.9843 - val_loss: 0.0497 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.04552\n",
      "Epoch 223/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0525 - acc: 0.9830 - val_loss: 0.0469 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.04552\n",
      "Epoch 224/500\n",
      "3637/3637 [==============================] - 0s 25us/step - loss: 0.0650 - acc: 0.9816 - val_loss: 0.0594 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.04552\n",
      "Epoch 225/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0592 - acc: 0.9821 - val_loss: 0.0628 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.04552\n",
      "Epoch 226/500\n",
      "3637/3637 [==============================] - 0s 24us/step - loss: 0.0567 - acc: 0.9819 - val_loss: 0.0467 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.04552\n",
      "Epoch 227/500\n",
      "3637/3637 [==============================] - 0s 26us/step - loss: 0.0511 - acc: 0.9841 - val_loss: 0.0495 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.04552\n",
      "Epoch 228/500\n",
      "3637/3637 [==============================] - 0s 27us/step - loss: 0.0508 - acc: 0.9852 - val_loss: 0.0518 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.04552\n",
      "Epoch 229/500\n",
      "3637/3637 [==============================] - 0s 23us/step - loss: 0.0530 - acc: 0.9841 - val_loss: 0.0500 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.04552\n"
     ]
    }
   ],
   "source": [
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    #    \n",
    "    model_dir = './model/'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    modelName = model_dir + 'model_day4.model'\n",
    "    #val_loss   ! \n",
    "    checkpointer = ModelCheckpoint(filepath=modelName, monitor='val_loss', verbose = 1, save_best_only=True)\n",
    "    \n",
    "    \n",
    "    # ! 30   stop!\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=30)\n",
    "    \n",
    "    #validation_split  x_train, y_train 0.2      !\n",
    "    \n",
    "    \n",
    "    # epochs  !\n",
    "    history = model.fit(X_train, y_train, validation_split = 0.2, epochs=500, batch_size=150, callbacks=[checkpointer, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950/1950 [==============================] - 0s 27us/step\n",
      " : 0.9810 \n"
     ]
    }
   ],
   "source": [
    "print(\" : %.4f \" % model.evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss'][1:]\n",
    "\n",
    "y_acc = history.history['acc'][1:]\n",
    "\n",
    "x_len = np.arange(len(y_acc))\n",
    "\n",
    "plt.plot(x_len, y_vloss, \"o\", c='red', markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c='blue', markersize=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
